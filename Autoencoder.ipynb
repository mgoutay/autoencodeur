{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Physical Layer as an Autoencoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First : change the runtime and hardware acceleration**\n",
    "\n",
    "Runtime $\\rightarrow$ Change runtime type\n",
    "\n",
    "- Runtime type : Python 3\n",
    "- Hardware accelerator : GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An autoencoder is a type of artificial neural network used to find a useful representation of some data $\\mathbf{s}$ at an intermediate layer $\\mathbf{x}$ through learning to reproduce the input at the output.\n",
    "\n",
    "![autoencoder_0](https://github.com/mgoutay/autoencodeur/blob/master/Images/autoencoder_0.png?raw=true)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install TensorFlow 2.0 on Google Collab if needed\n",
    "try:\n",
    "  # %tensorflow_version only exists in Colab.\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version:  2.0.0\n",
      "Number of GPUs available : 4\n",
      "Only GPU number 0 used\n"
     ]
    }
   ],
   "source": [
    "#Set the GPU you want to use\n",
    "num_GPU = 0\n",
    "\n",
    "import tensorflow as tf\n",
    "print('Tensorflow version: ', tf.__version__)\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "print('Number of GPUs available :', len(gpus))\n",
    "\n",
    "if num_GPU < len(gpus):\n",
    "    tf.config.experimental.set_visible_devices(gpus[num_GPU], 'GPU')\n",
    "    tf.config.experimental.set_memory_growth(gpus[num_GPU], True)\n",
    "    print('Only GPU number', num_GPU, 'used')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import sys\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt  \n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Layer, Dense, Lambda\n",
    "from tensorflow.keras.regularizers import Regularizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Communicating messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**An autoencoder-based communication systems aims to implement the transmitter, channel, and receiver as a single NN which reconstructs its input at its output**\n",
    "\n",
    "The goal is to learn a modulation wich will be robust with respect to the perturbations introduced by the channel.\n",
    "\n",
    "The channel is implemented as a \"Noise Layer\" without any learnable parameters, wich must be differentiable in order to perform SGD on the transmitter's parameters.\n",
    "\n",
    "Examples:\n",
    "\n",
    "- AWGN channel : $\\mathbf{y} = \\mathbf{x} + \\mathbf{w}$\n",
    "\n",
    "- Memoryless fading channel : $\\mathbf{y} = h \\mathbf{x} + \\mathbf{n} $\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![autoencoder](https://github.com/mgoutay/autoencodeur/blob/master/Images/autoencoder.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's transmit messages.\n",
    "\n",
    "The first hyper-parameters to set are the total number of messages $M$ and the number of channel uses $N_c$\n",
    "\n",
    "It can be seen that $M$ can also be seen as the modulation order. Indeed, sending one out of $M$ message is equivalent to sending $\\log_2(M)$ bits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will implement the fowllowing network:\n",
    "![model_0](https://github.com/mgoutay/autoencodeur/blob/master/Images/model_0.png?raw=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of messages\n",
    "M = 16\n",
    "\n",
    "# Number of channel uses\n",
    "ch_uses = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transmitter(Layer):\n",
    "\n",
    "    def __init__(self, M, ch_uses=1, **kwargs):\n",
    "        super(Transmitter, self).__init__(**kwargs)\n",
    "        self.M = M\n",
    "        self.ch_uses = ch_uses\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.emb_table = self.add_weight(shape=[self.M, 2*self.ch_uses], \n",
    "                                          initializer='random_normal',\n",
    "                                          trainable=True)\n",
    "\n",
    "    def call(self, messages):\n",
    "        #Embedding\n",
    "        self.x = tf.nn.embedding_lookup(self.emb_table, messages)\n",
    "        \n",
    "        # Normalize power per symbol to 1\n",
    "        self.en_moy =tf.sqrt(2 * tf.reduce_mean(tf.square(self.emb_table)))\n",
    "        self.x_norm = tf.divide(self.x, self.en_moy)\n",
    "        \n",
    "        #Real to complex\n",
    "        self.x_cplx = tf.complex(self.x_norm[:, :int(self.ch_uses)], self.x_norm[:, int(self.ch_uses):])\n",
    "            \n",
    "        return self.x_cplx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Channel(Layer):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Channel, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, x, noise_stddev):\n",
    "            \n",
    "        self.noise_r = tf.random.normal(shape = tf.shape(x), stddev = 1) * noise_stddev/tf.sqrt(2.)\n",
    "        self.noise_i = tf.random.normal(shape = tf.shape(x), stddev = 1) * noise_stddev/tf.sqrt(2.)\n",
    "        self.noise_cplx = tf.complex(self.noise_r, self.noise_i, name=\"noise\")\n",
    "        \n",
    "        self.y = x + self.noise_cplx\n",
    "            \n",
    "        return self.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Receiver(Layer):\n",
    "\n",
    "    def __init__(self, M, **kwargs):\n",
    "        super(Receiver, self).__init__(**kwargs)\n",
    "        self.M = M\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.dense_0 = Dense(4*self.M, activation = tf.nn.relu)\n",
    "        self.dense_1 = Dense(2*self.M, activation = tf.nn.relu)\n",
    "        self.dense_2 = Dense(self.M, activation = None)\n",
    "\n",
    "    def call(self, y):\n",
    "        # Complex to Real\n",
    "        self.y_real = tf.concat([tf.math.real(y), tf.math.imag(y)], axis=1)\n",
    "        \n",
    "        #Dense layers\n",
    "        self.d_0 = self.dense_0(self.y_real)\n",
    "        self.d_1 = self.dense_1(self.d_0)\n",
    "        self.d_2 = self.dense_2(self.d_1)\n",
    "        \n",
    "        #Softmax\n",
    "        self.p_s = tf.nn.softmax(self.d_2)\n",
    "        \n",
    "        return self.p_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(Model):\n",
    "\n",
    "    def __init__(self, M, ch_uses=1, **kwargs):\n",
    "        super(Autoencoder, self).__init__(**kwargs)\n",
    "        self.M = M\n",
    "        self.ch_uses = ch_uses\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.tx = Transmitter(self.M, self.ch_uses)\n",
    "        self.ch = Channel()\n",
    "        self.rx = Receiver(self.M)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        \n",
    "        self.messages, self.snr = inputs\n",
    "        self.noise_stddev = tf.sqrt( 2 / tf.pow(10., self.snr/10.0))\n",
    "        \n",
    "        self.x = self.tx(self.messages)\n",
    "        self.y = self.ch(self.x, self.noise_stddev)\n",
    "        self.p_s = self.rx(self.y)\n",
    "        \n",
    "        return self.p_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate the autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SNR at training\n",
    "training_snr = 15\n",
    "\n",
    "# Instantiate an autoencoder\n",
    "autoencoder = Autoencoder(M, ch_uses)\n",
    "\n",
    "#Initialize optimizer\n",
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ds_msgs(epoch_len, batch_size, M, training_snr):\n",
    "    'Generate epoch_len batches of messages'\n",
    "    \n",
    "    rand_msg = tf.random.uniform(shape=[epoch_len, batch_size], minval=0, maxval=M, dtype=tf.int32)\n",
    "    msg_ds = tf.data.Dataset.from_tensor_slices(rand_msg)\n",
    "    snr_ds = tf.data.Dataset.from_tensor_slices(training_snr*tf.ones(shape=[epoch_len, batch_size, 1]))\n",
    "    \n",
    "    features_ds = tf.data.Dataset.zip((msg_ds, snr_ds))\n",
    "    labels_ds = msg_ds\n",
    "    return (features_ds, labels_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What about the loss function?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss function is the **sparse** (there is only one good class) **categorical cross-entropy**:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "L(\\theta_T, \\theta_R) &= \\mathbb{E}_{m, y} - \\log(\\hat{\\mathbf{p_{\\theta_R}}}(m | y)), y \\thicksim p(y|x)\\\\\n",
    "&= H(m) - I_{\\theta_T}(m; y) + \\mathbb{E}_{s, y} [ D_{KL} (\\mathbf{p_{\\theta_R}}(m|y) || \\hat{\\mathbf{p_{\\theta_R}}}(m|y)) ]\\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "- $H(m)$ is the entropy  of the source\n",
    "\n",
    "- $I_{\\theta_T}(m; y) = I_{\\theta_T}(m; y)$ is the mutual information between the sent and the received symbols\n",
    "\n",
    "- $D_{KL} (\\mathbf{p_{\\theta_R}}(m|y) || \\hat{\\mathbf{p_{\\theta_R}}}(m|y))$ is the KL-Divergence between the true and the predicted distributions\n",
    "\n",
    "Hence, minimizing the sparse categorical cross-entropy loss both maximize the mutual information and minimize the KL-divergence between the true and the predicted distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = tf.keras.losses.SparseCategoricalCrossentropy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SER after each epoch:\n",
      "0.101, 0.0967, 0.0908, 0.0943, 0.0981, 0.0947, 0.0902, 0.0927, 0.0942, 0.0881, \n",
      "\n",
      "Execution time : 17.324588775634766 seconds\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10000\n",
    "epoch_size = 100\n",
    "nb_epoch = 10\n",
    "\n",
    "print('SER after each epoch:')\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(nb_epoch):\n",
    "    \n",
    "    # Create a dataset for each epoch\n",
    "    dataset = tf.data.Dataset.zip(generate_ds_bits(epoch_size, batch_size, M, training_snr))\n",
    "\n",
    "    # Iterate over the batches of the dataset.\n",
    "    for step, (features, labels) in enumerate(dataset):\n",
    "        # Open a GradientTape.\n",
    "        with tf.GradientTape() as tape:\n",
    "\n",
    "            # Forward pass.\n",
    "            p_s = autoencoder(features)\n",
    "\n",
    "            # Loss value for this batch.\n",
    "            loss_value =  loss_func(y_true=labels, y_pred=p_s)\n",
    "\n",
    "        # Get gradients of loss wrt the weights.\n",
    "        gradients = tape.gradient(loss_value, autoencoder.trainable_weights)\n",
    "\n",
    "        # Update the weights of our linear layer.\n",
    "        optimizer.apply_gradients(zip(gradients, autoencoder.trainable_weights))\n",
    "    \n",
    "    #Take the argmax of the probability distribution as the estimated message\n",
    "    m_hat = tf.argmax(p_s, axis=1, output_type=tf.int32)\n",
    "    \n",
    "    ser = tf.reduce_sum(tf.clip_by_value(tf.abs(labels-m_hat), 0, 1))/(batch_size)\n",
    "    print(ser.numpy(), end=', ')\n",
    "\n",
    "print(\"\\n\\nExecution time : %s seconds\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See learned constellation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = autoencoder.x.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f86382d1dd8>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(np.real(x), np.imag(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Communicating bits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of bits per symbols\n",
    "K = 4\n",
    "M = np.power(2, K)\n",
    "\n",
    "# Number of channel uses\n",
    "ch_uses = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(Layer):\n",
    "\n",
    "    def __init__(self, K, ch_uses=1, **kwargs):\n",
    "        super(Encoder, self).__init__(**kwargs)\n",
    "        self.K = K\n",
    "        self.M = int(2**self.K)\n",
    "        self.ch_uses = ch_uses\n",
    "        self.bin_conv = tf.convert_to_tensor(np.flip([np.power(2, i) for i in range(self.K)]).astype(np.int32)) # (8, 4, 2, 1)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.emb_table = self.add_weight(shape=[self.M, 2*self.ch_uses], \n",
    "                                          initializer='random_normal',\n",
    "                                          trainable=True)\n",
    "\n",
    "    def call(self, bits):\n",
    "        self.bits_k = tf.reshape(bits, [-1, self.K])\n",
    "        self.s = tf.reduce_sum(self.bits_k*tf.expand_dims(self.bin_conv,axis= 0), axis=1)\n",
    "        self.x = tf.nn.embedding_lookup(self.emb_table, self.s)\n",
    "        \n",
    "        # Normalize power per symbol to 1\n",
    "        self.en_moy =tf.sqrt(2 * tf.reduce_mean(tf.square(self.emb_table)))\n",
    "        self.x_norm = tf.divide(self.x, self.en_moy)\n",
    "        #Real to complex\n",
    "        self.x_cplx = tf.complex(self.x_norm[:, :int(self.ch_uses)], self.x_norm[:, int(self.ch_uses):])\n",
    "            \n",
    "        return self.x_cplx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Channel(Layer):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Channel, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, x, noise_std):\n",
    "            \n",
    "        self.noise_r = tf.random.normal(shape = tf.shape(x), stddev = 1) * noise_std/tf.sqrt(2.)\n",
    "        self.noise_i = tf.random.normal(shape = tf.shape(x), stddev = 1) * noise_std/tf.sqrt(2.)\n",
    "        self.noise_cplx = tf.complex(self.noise_r, self.noise_i, name=\"noise\")\n",
    "        \n",
    "        self.y = x + self.noise_cplx\n",
    "            \n",
    "        return self.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(Layer):\n",
    "\n",
    "    def __init__(self, K, **kwargs):\n",
    "        super(Decoder, self).__init__(**kwargs)\n",
    "        self.K = K\n",
    "        self.M = int(2**self.K)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.dense_0 = Dense(2*self.M, activation = tf.nn.relu)\n",
    "        self.dense_1 = Dense(self.M, activation = tf.nn.relu)\n",
    "        self.dense_2 = Dense(self.K, activation = None)\n",
    "\n",
    "    def call(self, y):\n",
    "        \n",
    "        self.y_real = tf.concat([tf.math.real(y), tf.math.imag(y)], axis=1)\n",
    "        self.d_0 = self.dense_0(self.y_real)\n",
    "        self.d_1 = self.dense_1(self.d_0)\n",
    "        self.d_2 = self.dense_2(self.d_1)\n",
    "        self.b_hat = tf.reshape(self.d_2, [-1])\n",
    "        \n",
    "        return self.b_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(Model):\n",
    "\n",
    "    def __init__(self, K, ch_uses=1, **kwargs):\n",
    "        super(Autoencoder, self).__init__(**kwargs)\n",
    "        self.K = K\n",
    "        self.M = int(2**self.K)\n",
    "        self.ch_uses = ch_uses\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.encoder = Encoder(self.K, self.ch_uses)\n",
    "        self.channel = Channel()\n",
    "        self.decoder = Decoder(self.K)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        \n",
    "        self.bits, self.snr = inputs\n",
    "        \n",
    "        self.noise_std = tf.sqrt( 2 / tf.pow(10., self.snr/10.0))\n",
    "        \n",
    "        self.x = self.encoder(self.bits)\n",
    "        self.y = self.channel(self.x, self.noise_std)\n",
    "        self.b_hat = self.decoder(self.y)\n",
    "        \n",
    "        return self.b_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ds_bits(epoch_len, batch_size, M, training_snr):\n",
    "    'Generate epoch_len batches of messages'\n",
    "    \n",
    "    rand_msg = tf.random.uniform(shape=[epoch_len, batch_size], minval=0, maxval=M, dtype=tf.int32)\n",
    "    msg_ds = tf.data.Dataset.from_tensor_slices(rand_msg)\n",
    "    snr_ds = tf.data.Dataset.from_tensor_slices(training_snr*tf.ones(shape=[epoch_len, batch_size, 1]))\n",
    "    \n",
    "    features_ds = tf.data.Dataset.zip((msg_ds, snr_ds))\n",
    "    labels_ds = msg_ds\n",
    "    return (features_ds, labels_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instantiate an  autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SNR at training\n",
    "training_snr = 15\n",
    "\n",
    "# Instantiate an autoencoder\n",
    "autoencoder = Autoencoder(M, ch_uses)\n",
    "\n",
    "#Initialize optimizer\n",
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER after each epoch:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Encoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-a820f9624923>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;31m# Forward pass.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mp_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;31m# Loss value for this batch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    885\u001b[0m         \u001b[0;31m# Eager execution on data tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 887\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    888\u001b[0m           \u001b[0mcast_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m           with base_layer_utils.autocast_context_manager(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2139\u001b[0m         \u001b[0;31m# operations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2140\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2141\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2142\u001b[0m       \u001b[0;31m# We must set self.built since user defined build functions are not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2143\u001b[0m       \u001b[0;31m# constrained to set self.built.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-39-ee20f9b63592>\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTransmitter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mch_uses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mChannel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReceiver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-2730800d8549>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, M, ch_uses, **kwargs)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mch_uses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEncoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mch_uses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mch_uses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Encoder' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER after each epoch:\n",
      "0.20965, 0.1574, 0.115525, 0.091375, 0.06895, 0.053125, 0.04455, 0.040375, 0.039375, 0.035125, \n",
      "\n",
      "Execution time : 19.777037143707275 seconds\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10000\n",
    "epoch_size = 100\n",
    "nb_epoch = 10\n",
    "\n",
    "print('BER after each epoch:')\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(nb_epoch):\n",
    "    \n",
    "    # Create a dataset for each epoch\n",
    "    dataset = tf.data.Dataset.zip(generate_ds_bits(epoch_size, batch_size, K, snr))\n",
    "\n",
    "    # Iterate over the batches of the dataset.\n",
    "    for step, (features, labels) in enumerate(dataset):\n",
    "        # Open a GradientTape.\n",
    "        with tf.GradientTape() as tape:\n",
    "\n",
    "            # Forward pass.\n",
    "            b_hat_log = autoencoder(features)\n",
    "\n",
    "            # Loss value for this batch.\n",
    "            loss_value =  loss_func(labels, b_hat_log, from_logits=True)\n",
    "\n",
    "        # Get gradients of loss wrt the weights.\n",
    "        gradients = tape.gradient(loss_value, autoencoder.trainable_weights)\n",
    "\n",
    "        # Update the weights of our linear layer.\n",
    "        optimizer.apply_gradients(zip(gradients, autoencoder.trainable_weights))\n",
    "\n",
    "    b_hat = tf.cast(tf.sign(b_hat_log)/2+1, dtype=tf.int32)\n",
    "    ber = tf.reduce_sum(tf.abs(b_hat - labels))/(batch_size*K)\n",
    "    print(ber.numpy(), end=', ')\n",
    "\n",
    "print(\"\\n\\nExecution time : %s seconds\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# See learned constellation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now directly see what's inside each class :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.7658981 -0.04487091j]\n",
      " [-0.26066825+0.7347326j ]\n",
      " [ 1.250048  -0.14272638j]\n",
      " ...\n",
      " [ 0.05869472+1.1574969j ]\n",
      " [-0.25172818-0.11254451j]\n",
      " [ 0.6742501 +0.2404414j ]]\n"
     ]
    }
   ],
   "source": [
    "x = autoencoder.x.numpy()\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f86383a3048>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(np.real(x), np.imag(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ds_bits(epoch_len, batch_size, K, snr):\n",
    "    'Generate a dataset for training'\n",
    "    rand_bits = tf.random.uniform(shape=[epoch_len, batch_size*K], minval=0, maxval=2, dtype=tf.int32)\n",
    "    bits_ds = tf.data.Dataset.from_tensor_slices(rand_bits)\n",
    "    snr_ds = tf.data.Dataset.from_tensor_slices(snr*tf.ones(shape=[epoch_len, batch_size, 1]))\n",
    "    \n",
    "    features_ds = tf.data.Dataset.zip((bits_ds, snr_ds))\n",
    "    labels_ds = tf.data.Dataset.from_tensor_slices(rand_bits)\n",
    "    return (features_ds, labels_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bits(batch_size, K):\n",
    "    'Generate a batch for evaluating'\n",
    "    rand_bits = tf.random.uniform(shape=[batch_size*K], minval=0, maxval=2, dtype=tf.int32)\n",
    "    features = rand_bits\n",
    "    labels = rand_bits\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, "
     ]
    }
   ],
   "source": [
    "snr_range = np.arange(-5, 26)\n",
    "results=[]\n",
    "bs_eval = 100000\n",
    "\n",
    "for snr in snr_range:\n",
    "    features, labels = generate_bits(bs_eval, K)\n",
    "    b_hat_log = autoencoder([features, snr])\n",
    "    b_hat = tf.cast(tf.sign(b_hat_log)/2+1, dtype=tf.int32)\n",
    "    ber = tf.reduce_sum(tf.abs(b_hat - labels))/(bs_eval*K)\n",
    "    results.append(ber.numpy())\n",
    "    print(snr, end=', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAE9CAYAAADj+KBFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deVhU9f4H8DcICKigoAgC4oYLmrvghlZqiolouVtZJC7ldvV2MbOynRYzU68mWpo/l1LrKijlkrtmo+zKqojsIKDs+/n9gc50UhFx5pxZ3q/n+T7OeuYz7+fIZ+ac7zljBEAAERER6SVjuQsgIiIizWGjJyIi0mNs9ERERHqMjZ6IiEiPsdETERHpMTZ6IiIiPWYidwGakJ2djeTkZLUtz8bGBnl5eWpbnq5jHirMQox5iDEPFWYhpu48XFxcYGdn99D7BX0bCoVCrcvz8/OT/T1p02AezIJ5MA9moV151NX3uOmeiIhIj7HRExER6TG92kc/btw4eHt7w87ODn379lXbctu2bavW5ek65qHCLMSYhxjzUGEWYlLmoVeNPjg4GMHBwVAoFAgNDVXbcvv166fW5ek65qHCLMSYhxjzUGEWYlLmwU33REREeoyNnoiISI/p1aZ77qOXBvNQYRZizEOMeagwCzHuo28g7qOXBvNQYRZizEOMeagwCzHuoyciIiK10Ktv9JrQtmd3WLu5oveYkagsK0NFaRnKS0tRUVqGytIyVNy9XFFWBqGmRu5yiYiIRNjoH6H3mJFwGOmJl0d6PvKxleXltU2/tBSVZeUoKy5GeXEJyktKav+9O8r+fr2kBOV3H1dWXIyyomKUFhahvKgYgiBI8A6JiEifsdE/wu/rA+FYaYT9//sVZhYWMLMwvzssYGp+97K5OcwsLVSX7z3O0gLmTZqghYM9GjexRGNLS5g3aQJT88aPfN2amhqUFRWhtKAIZYVFKCkoQGnhPy8XoqSgEKUFRSgtKETJnTu1990pRHVVlQTpEBGRttOrRq+pWfdtbGzh1MK29ooAoKQCKKmAgDsoB1D+mMszamQM08aNYWJuDlMLc5iYN4aphTlM7143s7SAqaVl7YeHJrX/WjdvjlZtHJS3m1qY1/kalaVlqCiu3VpQUXT33+ISVBQXo7zo3r/FKLtTiNI7BSgrKEB1RWW96ufsWRVmIcY8xJiHCrMQ46z7BjKkWffGJo1g0bQpLKyawcLKChbNmsLS2ur+YVX7r4VtC7To4AJLayuYmJo+cJllRcUovJWLwty82nHv8q1cFObm1/57Kxc3U1O1Lg+5aOO6ISfmIcY8VJiFmJR56FWjNyQ1VdUovn0HxbfvPPZzzSwsYGlthSYtrNHM1gbNWtqima3t3cu11+07dYDrwP6wtLJ64DI+fGni3cafh8K8POWHgIJb9z4Y1N5XnH+bcw2IiGTERm+Aao8UKMXtzKxHPtbEzAxNbVqgWUtbWN39EPD0c6MQn3xD+SGh7VNuaGZri8aWFvc9v7qqCkV5+Si4lYs7mVm4nZmN/Iws3M7IrL2cmYmCnFwesUBEpCFs9FSnqooK3M7MEn0oeKqFHX4JDLzvsWYWFqIPBLXDBla2trCyawlbZyd07N8XFlbNRM+rrqrCnewc3M7Iwu2sbNWHgIws5GdkIC81A+UlJRp/r0RE+oiNntSmorQUuSmpyE1JrfNx5k2boLl9azS3t0NzB3s0t7dDC/vaf9s+5Yaeo565bx5BUV4+8tIykJuahry0DOSlpSM3NR15qenIz8xETVW1Jt8aEZHOYqMnyZUVFSMz8ToyE68/8H4jIyM0tWmB5g72sHF0gI2jA2ydHGHj6AAnt67oOfIZNDJVrbo11dW4nZmNvLR05YeB7Bs3kXMjGTnJqagqf9zjIoiI9AcbPWkdQRCUM/9Toq/ed7+RsTGs7VrBxqkNbJ3awMaxjfLDQJchHrC2a6V8bE1NDfLTM5Fz4yaybyQjOym59nJSMgpybkn5toiIZKFXjZ6/XicNrcmjBqi+mYGcmxnI+dvNjcxMYWXfGlb2dmjm0BrWDq3RyqkNOvbvIzpZUWVpGQoys1CQkY2CjEzcSc/C7dQ0FGXl1PtIAa3JQkswDzHmocIsxHgcfQMZ0nH0ctLlPKxbt4JdOxfYtXdBq3ZtYdeuLVq1d0H7wQOUj6ksK0fm9SRkJlxDRvw1ZCTUjsJbufctT5ez0ATmIcY8VJiFGI+jJ9KQO1k5uJOVg4SLl0S3m5o3RusO7eDg2hH2rh3RpnMndBkyEAN8nlc+pjj/trLp3xtGpvwvRETajX+liFD7LT71ahxSr8aJbm/SojkcXDvWfgDo1AEOrh3hPnEcGltaAqidT+A/ZjhSr8Yi5UosUq/GIi0mnocDEpHWYKMnqkNx/m0k/nUZiX9dVt5mZGSEFo4OcHDtCO8Z05BdWoQO/fug7/OjAdROAMy5cfO+5l9RWirX2yAiA8ZGT/SYBEFA3t1j+Ad36oof7p48qJmtDZzcusKpe1c4u3VFpwH90G/cGAC1zT87KRmpdxt/ypVYpMfFo6K0TM63QkQGgI2eSE0Kc/MQc+Y8Ys6cV97WrKUtnNy6wrl7Vzi5dUXnQQPQf7wXgNrj/7Ou31A2/pQrMUiPS+Rx/0SkVmz0RBpUeCsXMafPIeb0OeVtVq1aqpp/967oOnSQctJfdVUVMhOvI/VqHFKuxCD1SizS4xNRXVm/nxAmIvonNnoiiRXk3MLVU2dx9dRZ5W3WrVvBuXu3u5v9u6HHM57weMEbAFBVWYmMhGtIvRKL+D8ViL/wF8oKi+Qqn4h0DBs9kRa4d9hf9B+nlbe1cLCvbfzdu8G5e1f0Hj0CgyZPQHVVFZIjohF79k/Enr2AtNh4GSsnIm3HRk+kpfIzMpGfkYmoYycBAMaNGqHtU93R1XMgug4dhLGL52Hs4nkoyLmF2HN/Ivbsn4i/8BdKCwrlLZyItIpeNXqeAlcazENFjiyyz11C9rlLMLe2gkOPbmjT0w29Rj4D9wnjUFNdjVvXbiA98grSI68i/2YqUM/T+aoD1w0x5qHCLMR4CtwG4ilwpcE8VGTP4sRJAHe/7fdwQ1fPQeg6dCB6TxqP3pPGo+BWLuLOXUTc+YtI+FOBorx8jZYjex5ahnmoMAsxngKXiB5LTXU1bkRE4UZEFH5bvxlNbVugy+CB6DZ0INyGD8EAn7EAgJSrsYg//xfizv2JG+FRqK6qkrlyItI0NnoiPVSUm4/LQSG4HBQCI2NjOHXrgs6D3dFliAeenjUDI2a/gvKSElxThCHu/J+IO/8Xcm7clLtsItIANnoiPSfU1CDlSgxSrsTgeOB2NG5iiU4D+qLLkIHoPMgdbsOHAADy0jIQd+Ei4s5dROJflzmpj0hPsNETGZjy4hJcOXkWV07WHsdv49QGXQZ5oPNgd/QePRKDJk1ATXU1EhWhCP/tGKKOnUTJnQKZqyaihmKjJzJweanpuLD3V1zY+yuMTRqhbY/u6OY5CL1Gj8CUVW/jxXfeQvxFBSJ+P46o46d4sh4iHcNGT0RKNVXVuBEeiRvhkQhZ9x0cu3ZG7zEj0Gv0SEz7aCUmveePuHMXEf77MVw5cQblxfw5XiJtx0ZPRA+VFhuPtNh4HPpmI5x7uKH3mBHoPXoEuj89FJXl5Yg9+yfCfzuGq6fO8Wd4ibQUGz0R1UtK9FWkRF9F8Or1cOnZA73GjECv557FUyOGo6K0DDFnzqNppYBGJiY8bI9Ii7DRE9FjEQRBecz+wS+/Rfu+vdB79Aj0HPUMmtna4L1BfRF66AgUBw4hPS5B7nKJDB4bPRE1mFBTg+uXwnD9Uhj+F7AGiz54D7nmjTB46kQMe3kq0mLi8df/ghB66Ahn7hPJhI2eiNSiproaxcmp2BEYCEtrK/QZ+xwGTHgeE99eBu9lC3Hl5Fn89b9gxJ//CzXV1XKXS2Qw2OiJSO1K7hTg3O59OLd7Hxw6d8SACePQ7/nR6PXcs7iTnYPLQSH463+HeDY+IgkYy13Ao7Rv3x5btmzB3r175S6FiBogI/4aDn6xFh+OGI8fFi9H6pVYDJ81A8uDfsLCHZvh8eJ4mFlYyF0mkd7SaKPfunUrsrKyEBUVJbp99OjRiI2NRUJCAvz9/etcRlJSEmbPnq3JMolIAtVVVYj+4xS+X/QffDTSB0FfrYN50yaYsuptvHf8IHz+swS2zk5yl0mkdzS66X7btm1Yv349fvzxR+VtxsbG2LBhA0aNGoXU1FQoFAocPHgQjRo1wmeffSZ6vq+vL3JycjRZIhHJoDA3Dye378LJ7bvg0qsHhk6fhMHTXsCwl6fi6ulzOLtrH+LPX4QgCHKXSqTzNNroz5w5AxcXF9Ft7u7uSExMRFJSEgBgz5498PHxQUBAALy9vTVZDhFpoeSIaCRHROPgl99i0OQJGDRlIuZsWoOcGzdxdvc+KA4c4hn4iJ6A5JPxHB0dkZKSoryempoKDw+Phz7exsYGn3zyCfr06YPly5cjICDggY/z8/PDnDlzAAAuLi7w8/NTW82enp5qW5Y+YB4qzELsifOoBtJ/CkZhp3aw6eWGiW8vxfhlC1EQk4D8yBhU5N9RT6ES4fqhwizEpMxD62fd5+XlYf78+Y98XGBgIAIDAwEACoVCeVld1L08Xcc8VJiFmDrzcHLriqEzJqOP10i06OWGuHN/4syufYg9c15nNutz/VBhFmLqzOPeF90HkXzWfVpaGpydnZXXnZyckJaWJnUZRKQDUq/GYs/Kj/DRqAkIWfcd7Dt1xOwNX2H5oZ/hOXMKTBo3lrtEIq0n+Td6hUIBV1dXtGvXDmlpaZg2bRpmzJihlmWPGzcO3t7esLOzQ9++fdWyTABo27atWpen65iHCrMQ02QeeZcicSgsGs79eqPLqKcxYfm/MHqeL64EH0HiyXOorqzUyOs+Ca4fKsxCTOo8BE2NXbt2Cenp6UJFRYWQkpIi+Pr6CgAELy8vIS4uTkhMTBRWrFih9tdVKBRqXZ6fn5/GMtLFwTyYhTbk0aFfb2HelnXC6qgLwnvHDwpDZ0wWTMzMZM+A6wezkCOPuvqeRr/RP+ybekhICEJCQjT50kSk565fDsem2QvRsX8fPPfGbEx8eyme9X0Zx7f+iIv7D6KqokLuEom0gtZPxnsc3HQvDeahwizEZMmjBri4fitudD2Nni+MwwsrlmHMPF9EB/2Oa6cvoEbGn8zl+qHCLMT0ZtO9XIOb7jU7mAez0OY8XD36Cwu2bxJWR10QVh75VRg0eaLQyMTEYPPQlsEsNJtHXX1P6891T0T0OBIuXsL6WfPw3ZxFuJOVg0nv/QfLD/2MgZN80MhErzZiEtULGz0R6aX4Cwqse3kONs9dgsKcXEx+fzmWB/+MvuNGw8jISO7yiCSjVx9vuY9eGsxDhVmIaWUeZZU4+/VGXHvKDb1eHIeZn63Cc6+/gss79yH3erJGX1or85AJsxDjPnoN7qtoyOC+JebBLPQjDyMjI6H/+LHC+38ECaujLgjTP3lPsLJrZbB5cN3Qnzy4j56ICIAgCLh08DACxk3FscDt6DX6WSwP+gkj/GbxLHukt9joicjglJeUIOTbTfjCZzpiz17A2EXz4H9gN3o+96zcpRGpHffR1wP3LYkxDxVmIaaLeUTv3I/sy5HoP3MSZq3+BFmxCbi8cx/yb6Y+8bJ1MQ9NYRZi3EevwX0VDRnct8Q8mIX+52FkbCwMnOQjfHDqsPBlxDlh8vvLhaa2LQw2D64bupUH99ETET2CUFODP/cdwGfjpuD0jj0Y4PM83g7ei6dfnYlGpqZyl0fUYGz0RER/U1ZYhKCv1uGLiTNw7VIYvJctwFu/7kTnQe5yl0bUIGz0REQPcCs5Bd8vfAub5y6BUFODuZvX4uUvP4JVq5Zyl0b0WDgZrx44iUSMeagwCzG9zKOsEsc//hpuY0fiKe8x6D58CCL2ByP++GkINTV1PlUv82ggZiHGyXganJTQkMFJJMyDWTAPAIKtk6Mwe+PXwuqoC8LSn7cLbXt2N+g8uG5oTx6cjEdEpAa5qWnYMn8ptv3rbTSxaY6FOzZj0nv+sLCykrs0oodioyciekxRx07ii/HTcXrHHrhPHAf/g7vRf/xYucsieiA2eiKiBigvKUHQV+uwZuqryE1Jw/RP3sUb2/6L1h3by10akQgbPRHRE8iIv4b1r8zFT+99CvuOHbBs7494/l9vwMzCXO7SiABw1n29cLaoGPNQYRZihpxHVXIaQt75BL2nTMCzvi/Dw+d5NIq9gb6XDTOPfzLkdeNBOOteg7MPGzI4W5R5MAvm8TijXe+ewlv/2yV8FXleGOE3SzAyMpK9JrkH1w3N5sFZ90REEroRHom1031REHcdYxfNw2vffgELq2Zyl0UGio2eiEgDKkrLkHHkFH75dDW6DPHAkj3fo00XV7nLIgPERk9EpEHndu/Df197AyZmZlj0f4EY4MPD8EhabPRERBqWHBGNNVNexY3wKEz7+F1Met8fJmZmcpdFBoKNnohIAkV5+dg8bwmOb/kRgyZNwIIfN6FFG3u5yyIDwMPr6oGHhYgxDxVmIcY8xB6UR+aZizhVVIpBc17BW/t34Nym7ciIuipThdLhuiHGw+s0eJhBQwYPC2EezIJ5qDsPW2cnYdn+HcKXEeeEUfN89f4QPK4bms2Dh9cREWmZ3JRUfDtzNkKDf8eYN/3w+oav+OM4pBFs9EREMqksK8fudz7Evo++gOvAAfjXTz/AsVtnucsiPcNGT0Qksws//4oNs+ahkUkjLNyxGb1Hj5C7JNIjbPRERFrgZtRVfD3lVaREx+Dlrz7GqHm+cpdEeoKNnohISxTn38Ymv0W4dDAEY970w8yAVTzenp6YXh1eR0Sk66orK7H7nQ+RnZSMsYvnwcaxDX5Y7I+ivHy5SyMdxW/0RERa6PiW7di+dAUcu3bGop1bYN+pg9wlkY5ioyci0lKRR09gw6vzYdrYDAt3bEaXIQPlLol0EBs9EZEWS7kSg7XTX0duShpmb/gKQ6ZPkrsk0jF6tY+ep8CVBvNQYRZizENMnXmcXbMJg+e9ihdWLEN39/64vHMfhJoatSxbClw3xHgKXA2eCrAhg6duZB7MgnloQx5GxsbCuKULhNVRFwS/jWsE86ZNZH+PXDe0Iw+eApeISA8INTUI/no9fn7/U7h69MfCHZth4+ggd1mk5djoiYh0zMVfgrB53hJY2bXEop1b0K7XU3KXRFqMjZ6ISAcl/nUZa2fMRllRMeZ/vx49Rz0jd0mkpdjoiYh01K3kFHw7czZSomPw0ucfovsznnKXRFqIjZ6ISIeV3ClA4BtLkXo1Fq989TGPtaf7sNETEem48uISBL6xFJmJSXjtmwB0cu8nd0mkRdjoiYj0QGlBITbPXYxbKanwXfcl2vfpKXdJpCXY6ImI9ETx7TvY5LcQd7KyMfu/X8O5h5vcJZEWYKMnItIjRbn52Dh7IYry8zHnuzVw7NpZ7pJIZmz0RER6piA7B5teX4jy4hLM3bwWrTu2l7skkhEbPRGRHsrPyMTG1xeiqrIS87asQ0sXZ7lLIpmw0RMR6anclFRsmr0QRkZGmL91PWyc2shdEsmAjZ6ISI9lJyXjuzmLYNq4MeYFrkNz+9Zyl0QS04lG7+Pjg82bN2PPnj0YNWqU3OUQEemUjPhr2Dx3MSytmmHelnWwatVS7pJIQhpv9Fu3bkVWVhaioqJEt48ePRqxsbFISEiAv79/ncs4cOAA5syZg3nz5mHq1KmaLJeISC+lXo1D4BtLYdXKFnMDv0VTmxZyl0QS0Xij37ZtG8aMGSN+UWNjbNiwAV5eXnBzc8P06dPRrVs39OjRA0FBQaLRqlUr5fNWrlyJDRs2aLpkIiK9lBwRjS1v/hs2bRwwd/NaWFhZyV0SScBE0y9w5swZuLi4iG5zd3dHYmIikpKSAAB79uyBj48PAgIC4O3t/cDlBAQEICQkBGFhYQ+838/PD3PmzAEAuLi4wM/PT23vwdOTPxTxd8xDhVmIMQ8xbc0j87eTcPIeiXd+2YmUX0NQU1Gp8dfU1izkImUeGm/0D+Lo6IiUlBTl9dTUVHh4eDz08QsXLsTIkSNhbW2NTp064bvvvrvvMYGBgQgMDAQAKBQK5WV1UffydB3zUGEWYsxDTFvz6HbsGF77JgDo3RXfv7EM1ZWab/bamoVc1JnHvS+6D6ITk/HWrVuH/v37Y/78+Q9s8kRE9HhiTp/DT+9/is4DB2DGp+/ByFgn2gE1gCzf6NPS0uDsrDp5g5OTE9LS0p54uePGjYO3tzfs7OzQt2/fJ17ePW3btlXr8nQd81BhFmLMQ0zb8xDSshC65xf0nfYCLExMcWnHzxp7LW3PQmpS5yFoeri4uAhRUVHK640aNRKuXbsmtGvXTjA1NRXCw8MFNzc3tb2eQqFQa/1+fn4az0iXBvNgFsxDv/LwXrZQWB11QRjhN8vgs5BqqDuPuvqexrfV7Nq1CxcuXECXLl2QkpICX19fVFdXY8GCBfj9998RExODn3/+GVevXtV0KURE9ADBX6/HpYMhGLtoHjxeePCEaNJdGt90P2PGjAfeHhISgpCQELW+FjfdS4N5qDALMeYhpkt5xP/vMBxc2mLS+8vR2sYWqaGRal2+LmUhBb3bdC/14KZ7zQ7mwSyYh37mYWZhLizauUUIuHRS6NCvt0FnoemhV5vuiYhIN1SUlmHrm8uQn54J32+/gL1rR7lLIjVgoyciIqXi23ewee4SlJeWYs6mNWjRxl7ukugJyXJ4naZwH700mIcKsxBjHmK6nMfZtZsx6p2lWLRtE458vBrlRcVPtDxdzkITuI9eg/sqGjK4b4l5MAvmYYh5tO/TUwhQnBQW79oqmFlYGHQW6h7cR09ERLJLCovEjrdWwsmtC15d8ykamejVRmCDwUZPREQPdeXkWez94HN0GTIQUz96B0ZGRnKXRI9Jrz6ecR+9NJiHCrMQYx5i+pJHVXIawvceQL/JPrA0MUXo7l8eexn6koW6SJmHXjX64OBgBAcHQ6FQIDQ0VG3L7devn1qXp+uYhwqzEGMeYvqUR2hoKArKyzDspalIjL6Kk9t3Pdbz9SkLdZAyjwZture2tsaKFSvUXQsREWmxg1+sRfjvx/H80jfR/emhcpdD9VRno3dycsJ3332HoKAgvP7667C0tMRXX32F+Ph42NnZSVUjERFpAUEQsGflR0i9GouZn38Ah86d5C6J6qHORv/jjz8iPT0d69atQ/fu3XHp0iW0adMGPXv2xJIlS6SqkYiItERlWTl+WOSP0sIivL7+SzSztZG7JHqEOvfR29jY4IMPPgAAHDlyBJMnT8bMmTMhCIIkxT0uTsaTBvNQYRZizENMn/M4v+F7PPfOv/DmlnU4FrAWNZVVdT5en7NoCK2ajNe8eXPl4RS5ubmwtrZWXs/Pz9dsdY+Jk/GkwTxUmIUY8xDT6zxCQ5FdcBuvfhOALhPHYufyVXU+XK+zaAAp86iz0VtbW+Py5cui4ybvFSYIAjp25A8eEBEZqqjjp3B47SaMXTwPWddv4NjmbXKXRA9QZ6Nv3769VHUQEZEOOr5lO+w6uMBr4VxkJyUj8ugJuUuif6hzMt7MmTOVlwcPHiy6780339RMRUREpFP2rgpAUlgkpn/yHpzcuspdDv1DnY1+6dKlysvr1q0T3efr66uZioiISKdUVVRg25LlKMrPh++3X8DKrpXcJdHf1Lnp/u/75v95fmNtPN8xZ91Lg3moMAsx5iFmaHlc2PA9nlu5DAu2rMPRT9eguqJSeZ+hZfEoWjPr/u+H0f3zkDptPMSOs+6lwTxUmIUY8xAzuDxCQ5FxOx++675At8njsePfK5W9wuCyeAStmXXftWtXREREwMjICB07dkRERASA2m/zHTp0kKRAIiLSHTGnzyF49XqMf2sRst/0w2/rN8tdksGrs9F369ZNqjqIiEhPnPpxN1p3aIdRc19D1vUbCDt8RO6SDFqdjf7mzZv33WZra4vc3FyNFURERLpv/8dfwratE6Z+uAK5qWlyl2PQ6px17+HhgRMnTmD//v3o3bs3oqKiEB0djaysLIwePVqqGomISMdUV1Vh+7/exp2sHLy29nOYNG0id0kGq85Gv379enz66afYvXs3/vjjD8yePRsODg4YNmwYPvvsM6lqJCIiHVRypwBbF/wbpmZmcPIeBVPzxnKXZJDqbPQmJiY4evQo9u3bh8zMTFy8eBEAEBcXJ0lxRESk27KTkrHjrXfRuGULjH9rsdzlGKQ699HX1NQoL5eWloru08bD63gcvTSYhwqzEGMeYszjrrJKVCUmY/CUiajMyEZqaKTcFclOa46j79WrF+7cuQMjIyNYWFjgzp07AGoPrzM3N5ekwMfB4+ilwTxUmIUY8xBjHir9fj+JJpUD0f+VqTh5IBgFObfkLklWUq4bj9x0b21tDSsrK5iamsLa2lp53czMTJICiYhID9TUYKf/+zBp3BjTP31PK8+uqq/qbPRERETqknPjJg588Q06DxyAYS9Pk7scg8FGT0REkrm4/yAij53E2CXz4di1s9zlGAQ2eiIiktTeVZ+hOO82Zn7+AQ+5kwAbPRERSarkTgF2v/MhWrVry0PuJMBGT0REkku4eAmntu3C4CkT0ePZYXKXo9fY6ImISBYh675DytVYTFn1NqxatZS7HL3FRk9ERLKorqriIXcSqPOEObqGZ8aTBvNQYRZizEOMeajUlUXYnl8w0HcmZqz4N2JCjktcmTykXjcEfRsKhUKty/Pz85P9PWnTYB7MgnkwD3VnMWvNZ8LnoacFx26dZa9VG/J43FFX3+OmeyIikt3eVZ+hKC8fL33+IcwstO8U67qMjZ6IiGRXcqcAu1d8iJYuzvD+9yK5y9ErbPRERKQVEv+6jJPbdvKQOzVjoyciIq3x27rNPOROzdjoiYhIa/CQO/VjoyciIq3y91+5G/7KdLnL0Xls9EREpHXu/cqd16K5sO/UQe5ydBobPRERaaV9H36O0sIiTP/kPTQy0avzu0mKjZ6IiLRScf5t7Pvwczi5dcHIua/JXY7OYqMnIiKtFf3HafIF3rsAABXTSURBVCgOHMaI2a/AuYeb3OXoJDZ6IiLSav/7fA0Kcm5hxqfvwaRxY7nL0Tls9EREpNXKCovw07ufwK69C55fPF/ucnQOGz0REWm9hIuXcHbXXgx7eSo6DuAvAj4OrW/0Xbt2xcaNG7F3717MmzdP7nKIiEgmwWs2IOfGTUz7eCUaN7GUuxydodFGv3XrVmRlZSEqKkp0++jRoxEbG4uEhAT4+/vXuYzY2FjMnz8fU6ZMwZAhQzRZLhERabHKsnLseudDNG9thwn+/5K7HJ2h0Ua/bds2jBkzRvyCxsbYsGEDvLy84ObmhunTp6Nbt27o0aMHgoKCRKNVq1YAAG9vbxw6dAiHDx/WZLlERKTlbkZewR9bd8B94ji4DR8qdzk6QaON/syZM8jLyxPd5u7ujsTERCQlJaGyshJ79uyBj48PoqOj4e3tLRo5OTkAgKCgIIwdOxYzZ87UZLlERKQDjmzcirTYeExetRxNmlvLXY7Wk/xUQ46OjkhJSVFeT01NhYeHx0MfP3z4cLzwwgto3Lhxnd/o/fz8MGfOHACAi4sL/Pz81Fazp6en2palD5iHCrMQYx5izENF3VlUXL6CZtPG49/fb0R6yAm1LlsKUq4bWn9OwVOnTuHUqVOPfFxgYCACAwMBAAqFQnlZXdS9PF3HPFSYhRjzEGMeKurO4tmcDDy/5A0c3LINYYePqHXZUlBnHve+6D6I5LPu09LS4OzsrLzu5OSEtLQ0qcsgIiIdd+KHnbgRHoUX3lkGK7tWcpejtST/Rq9QKODq6op27dohLS0N06ZNw4wZM9Sy7HHjxsHb2xt2dnbo21d9x1m2bdtWrcvTdcxDhVmIMQ8x5qGiqSwid+3H2I/eht+aAJxYvUHty9cUqdcNQVNj165dQnp6ulBRUSGkpKQIvr6+AgDBy8tLiIuLExITE4UVK1ao/XUVCoVal+fn56exjHRxMA9mwTyYhzZlMXjqC8LqqAvCoMkTZX+fcuVRV9/T6Df6h31TDwkJQUhIiCZfmoiIDMT5n35Bj2eHwfvfCxB/4S/kpnJ38N9p/WS8x8FN99JgHirMQox5iDEPFU1nceXng2jf6ynMXvs5jn26BoIgaOy11EHKdUOvGn1wcDCCg4OhUCgQGhqqtuX269dPrcvTdcxDhVmIMQ8x5qEiRRZlFmaY8dn7sOrZFSd+2KnR13pSUq4bWn+ueyIiovq4HPwbIo+dxJgFc9CqXVu5y9EaevWNnpvupcE8VJiFGPMQYx4qUmWRcOA3dB3sgZc/WomTazZp/PUaSm9m3cs1OOtes4N5MAvmwTy0OYunX50prI66IHQZ7CH7+5Yqj7r6HjfdExGRXjmz82fcSknF+LcWwbhRI7nLkR0bPRER6ZXqykoEfbUe9p06YOAkH7nLkR330dcD97OJMQ8VZiHGPMSYh4rkWdwuRObVODy/eD5q0rJQUVIq3WvXA/fRa3BfRUMG97MxD2bBPJiH7mXh0LmT8GXEOWH8W4tkf/+azoP76ImIyOBkxCfi4i8HMXT6ZLR0cX70E/QUGz0REemt39ZvRmV5OcYvWyh3KbJhoyciIr1VlJuPY5t/QPdnPNF50AC5y5EFJ+PVAyfUiDEPFWYhxjzEmIeKnFkUXklAYXYOpr63HIff/QxCTY0sdfwdJ+NpcFJCQwYn1DAPZsE8mIduZ/HUiOG1P2U7RTt+ypaT8YiIiNQo6vgpJP51GV4L5sC8WVO5y5EUGz0RERmEA1+shYW1FUbNfU3uUiTFRk9ERAYhPS4Bf/0SBM8ZUwzqcDs2eiIiMhgh679DZXk5vJctkLsUyXDWfT1w5qwY81BhFmLMQ4x5qGhTFjGHjqLP1AkY+9J0ZF6Nk6UGzrrX4OzDhgy5Z4tq22AezIJ5MA9dzsLEzExYEbJP+Pcv/ycYN2qkF3lw1j0REdFdVRUVCPpqHRxcO8LjhfFyl6NxbPRERGRwoo6fQqIiFGMW+On94XZs9EREZJAOfrEWls2tMWqOfh9ux0ZPREQGKS02HopfgzF05mS0bOskdzkaw0ZPREQGK2Tdd6iqqNDrw+3Y6ImIyGAV5ubheOB29Hh2OFw9+stdjkbwOPp60KbjP7UB81BhFmLMQ4x5qGhzFgXRcSjMvoUp7/oj5P0AQBA0/po8jl6DxxM2ZGjT8Z/aMJgHs2AezEPfsugz9jlhddQFoY/XKJ3Mg8fRExER1SE85CjSYuMxZuEcNDLRq43d3EdPREQkCAIOr92Ils5OcH/BW+5y1IqNnoiICEDs2T9x7VIYnpvnCzMLc7nLURs2eiIiorsOf7MRVq1awnPmVLlLURs2eiIiortuREQh+sRpPOP7EiytreQuRy3Y6ImIiP4m5Nvv0LiJJZ71fVnuUtSCjZ6IiOhvMhOv43LQbxg6YzKsW7eSu5wnxkZPRET0D7//NxBGxkYYNc9X7lKeGBs9ERHRP+SnZ+L8T7/CfcI4tGrXVu5ynohenRWAp8CVBvNQYRZizEOMeajoYhbZF0NRM8kH09/1x9kNW9W6bJ4CV4OnAmzI0PZTN0o9mAezYB7Mw1CyeG7+68LqqAuCc/duWp0HT4FLRETUAKd+3I2ivHyMXTxP7lIajI2eiIjoIcqLS3AscDs6D3KH68ABcpfTIGz0REREdTj/0y/IS8/Q2W/1bPRERER1qK6sxO8btqBtDzf0HPWM3OU8NjZ6IiKiR7gc/BsyE6/Da+FcGDdqJHc5j4WNnoiI6BGEmhoc/nYT7Nq7YIDPWLnLeSxs9ERERPVw5cQZ3IiIwnNvzIZJ48Zyl1NvbPRERET1dOibjWje2g5Dp70odyn1xkZPRERUT9cvhSHmzHmM8JsF82ZN5S6nXtjoiYiIHsPhtZtgaW2FZ16dKXcp9cJGT0RE9BjS4xIQevgIPF+aimYtbeUu55HY6ImIiB7Tb+sDYWJqilFzX5O7lEfSiUZvaWkJhUKB559/Xu5SiIiIkJuSij/3H8DAF31g6+Qodzl10mij37p1K7KyshAVFSW6ffTo0YiNjUVCQgL8/f0fuRx/f3/8/PPPmiqTiIjosR397gfU1FRjxOxX5C6lThpt9Nu2bcOYMWPEL2hsjA0bNsDLywtubm6YPn06unXrhh49eiAoKEg0WrVqhZEjR+Lq1avIzs7WZKlERESPpfBWLv7cdwD9x49Fizb2cpfzUCaaXPiZM2fg4uIius3d3R2JiYlISkoCAOzZswc+Pj4ICAiAt7f3fct4+umn0aRJE7i5uaG0tBSHDx+GIAiaLJuIiKheTvzwfxg0eQKeff0V7P/oC7nLeSCNNvoHcXR0REpKivJ6amoqPDw8Hvr4lStXAgBmzZqFW7duPbTJ+/n5Yc6cOQAAFxcX+Pn5qa1mT09PtS1LHzAPFWYhxjzEmIeKPmdRGHsNg14cD7uiClQVFdfrOVLmIXmjb6jt27fXeX9gYCACAwMBAAqFQnlZXdS9PF3HPFSYhRjzEGMeKvqaRYvgILx9aC8yzY3x65r6v0d15nHvi+6DSD7rPi0tDc7OzsrrTk5OSEtLk7oMIiIitcjPyITiwCF4vDgeVq1ayl3OfST/Rq9QKODq6op27dohLS0N06ZNw4wZM9Sy7HHjxsHb2xt2dnbo27evWpYJAG3btlXr8nQd81BhFmLMQ4x5qOh7Fll/XkajieMwxf9fCN21/5GPlzoPQVNj165dQnp6ulBRUSGkpKQIvr6+AgDBy8tLiIuLExITE4UVK1ao/XUVCoVal+fn56exjHRxMA9mwTyYB7O4f0z96B0hQHFSaGZrI3kedfU9jX6jf9g39ZCQEISEhGjypYmIiCR1PHA7+nt7YfisGQj+er3c5SjpzGS8+uCme2kwDxVmIcY8xJiHiqFkkXzxMjxnTELu5UiUFxY99HF6s+lersFN95odzINZMA/mwSwePOzauwhfRpwTvBbNkzSPuvqeTpzrnoiISBdkJyUj4vfjGDpjEiysrOQuB4CO/KgNERGRrji2eRvMmzTBsJenyl0KAO6jrxdD2bdUX8xDhVmIMQ8x5qFiaFncVITh6Vem43bEVVSWlN53P/fRa3BfRUOGoexbYh7MgnkwD2ahntGmi6uwOuqCMGqeryR5cB89ERGRhNLjEhB94jSGvTQVjZtYyloLGz0REZEGHN30AyytrTBk2iRZ6+A++nowtH1Lj8I8VJiFGPMQYx4qhppFWng0Rrz+MoquJqCqvFx5O/fRa3BfRUOGoe1bYh7MgnkwD2ahntG2Z3dhddQF4elXZ2o0D+6jJyIiksHNyCuIO38RT786A6bmjWWpgY2eiIhIg45u+h7NbG0wcNIEWV6fjZ6IiEiDksIikXDxEp71fQkmjaX/Vs/JePVgqJNIHoZ5qDALMeYhxjxUDD2LG3+chatHf0xa/Abij53iZLwnHZyMp9nBPJgF82AezOLxxxvb/iu8e+yA0MjUlJPxiIiI9M3RTT+geWs7uE8YJ+nrstETERFJIOFPBW5EROHZ2S8DxtK1XzZ6IiIiiRzd9D1s2jjAumtHyV6Tk/HqwdAnkfwT81BhFmLMQ4x5qDCLu0oqkHs9Ga0H9OFkvCcZnIyn2cE8mAXzYB7MouHDvlMHYd6ihWpdJifjERERaYnMxOuoLi2T7PXY6ImIiPQYGz0REZEeY6MnIiLSY2z0REREeoyNnoiISI/xOPp64PGfYsxDhVmIMQ8x5qHCLMSkzEOvGn1wcDCCg4OhUCgQGhqqtuX269dPrcvTdcxDhVmIMQ8x5qHCLMSkzIOb7omIiPQYGz0REZEeY6MnIiLSY0aoPReuXsnOzkZycrLalteyZUvcunVLbcvTdcxDhVmIMQ8x5qHCLMTUnYeLiwvs7Oweer/sJ/jX9qHuH8nR9cE8mAXzYB7MQnfy4KZ7IiIiPcZGT0REpMcaAVgldxG6gMd/ijEPFWYhxjzEmIcKsxCTKg+9nIxHREREtbjpnoiISI+x0dfT+++/j9TUVISFhSEsLAxeXl5ylyS50aNHIzY2FgkJCfD395e7HNklJSUhMjISYWFhUCgUcpcjua1btyIrKwtRUVHK21q0aIEjR44gPj4eR44cQfPmzWWsUDoPysKQ/2Y4OTnhjz/+wJUrVxAdHY1FixYBMMz142FZSL1+yH6YgS6M999/X1i2bJnsdcg1jI2NhcTERKF9+/aCqampEB4eLnTr1k32uuQcSUlJgq2trex1yDU8PT2FPn36CFFRUcrbPv/8c8Hf318AIPj7+wsBAQGy1ylXFob8N8Pe3l7o06ePAEBo2rSpEBcXJ3Tr1s0g14+HZSHl+sFv9FQv7u7uSExMRFJSEiorK7Fnzx74+PjIXRbJ6MyZM8jLyxPd5uPjg+3btwMAtm/fjgkTJshRmuQelIUhy8zMRFhYGACgqKgIMTExcHR0NMj142FZSImN/jEsWLAAERER2Lp1q0Fscvo7R0dHpKSkKK+npqZKvrJqG0EQcOTIEVy6dAl+fn5yl6MVWrdujczMTAC1f+Bat24tc0XyMuS/Gfe4uLigT58+uHjxosGvH3/PApBu/WCj/5ujR48iKirqvjF+/Hhs3LgRHTt2RO/evZGRkYHVq1fLXS7JbOjQoejXrx+8vLzw5ptvwtPTU+6StI4gCHKXIBv+zQCaNGmC/fv3Y8mSJSgsLLzvfkNaP/6ZhZTrh179Hv2TGjVqVL0eFxgYiODgYA1Xo13S0tLg7OysvO7k5IS0tDQZK5Jfeno6ACAnJwe//vor3N3dcebMGZmrkldWVhbs7e2RmZkJe3t7ZGdny12SbP7+3g3xb4aJiQn279+PnTt34tdffwVguOvHg7KQcv3gN/p6sre3V16eOHEioqOjZaxGegqFAq6urmjXrh1MTU0xbdo0HDx4UO6yZGNpaYmmTZsqLz/33HMGt048yMGDBzFr1iwAwKxZs3DgwAGZK5KPof/N2Lp1K2JiYrBmzRrlbYa6fjwoC6nXD9lnJerC+PHHH4XIyEghIiJCOHDggGBvby97TVIPLy8vIS4uTkhMTBRWrFghez1yjvbt2wvh4eFCeHi4EB0dbZB57Nq1S0hPTxcqKiqElJQUwdfXV7CxsRGOHTsmxMfHC0ePHhVatGghe51yZWHIfzOGDBkiCIIgRERECGFhYUJYWJjg5eVlkOvHw7KQcv3gmfGIiIj0GDfdExER6TE2eiIiIj3GRk9ERKTH2OiJiIj0GBs9ERGRHmOjJyIi0mNs9EQGbsWKFYiOjkZERATCwsLg7u6OEydOiH56t1+/fjhx4gQAYPjw4bh9+zbCwsIQExODL7/8UrQ8Hx8fvPvuuw98rXunQXVxcUFJSQnCwsIQHh6Oc+fOoXPnzgCAHj164IcfftDEWyUyWLKfUICDg0OeMXDgQOH8+fOCmZmZAECwtbUVHBwchBMnTgjJycnCmDFjBABCv379hBMnTggAhOHDhwtBQUECAMHc3FyIiYkRBg8erFzmuXPnHvrzvYWFhQIAwcXFRfSTrnPmzBG2bdumvH706FHB2dlZ9nw4OPRh8Bs9kQFzcHDArVu3UFFRAQDIzc1FRkYGAODLL7/EO++8U+fzy8rKEB4ervwlQ1dXV5SXlyM3NxcA0K5dO5w/fx6RkZH46KOPHrocKysr5OfnK68HBQVh2rRpT/TeiKgWGz2RATty5AicnZ0RFxeHDRs2YNiwYcr7Lly4gIqKCjz99NMPfX7z5s3h6uqK06dPAwCGDBmC0NBQ5f1r167Fxo0b0bNnT+UHiHs6duyIsLAwJCYmYunSpfj666+V9126dIm/BkikJmz0RAasuLgY/fr1w5w5c5CTk4OffvpJ+aMjAPDxxx9j5cqV9z3P09MT4eHhSEtLw++//46srCwAtVsIcnJylI8bMmQIdu/eDQDYsWOHaBnXrl1Dnz590KlTJyxZsgSbN29W3pednY02bdqo9b0SGSo2eiIDV1NTg1OnTmHVqlVYsGABXnzxReV9J06cgIWFBQYOHCh6zpkzZ9C7d290794dr7/+Onr16gUAKC0thbm5ueix9fnN8YMHD4q2Jpibm6O0tPRJ3hYR3cVGT2TAOnfujE6dOimv9+7dG8nJyaLHfPzxx/jPf/7zwOffuHEDAQEB8Pf3BwDExMSIlnfu3DnlvvaZM2c+tI6hQ4fi2rVroroM7WddiTSFjZ7IgDVt2hTbt2/HlStXEBERATc3N6xatUr0mJCQENHm+H/atGkThg0bBhcXF5w+fRp9+vRR3rd48WK8+eabiIyMVE7Yu+fePvrw8HB8+umnmD17tvK+Z555BocOHVLPmyQycPyZWiJSq2+++QZBQUE4fvx4g55vZmaGU6dOYejQoaiurlZzdUSGh42eiNTKzs4OHh4eCAoKatDzO3XqBEdHR5w6dUrNlREZJjZ6IiIiPcZ99ERERHqMjZ6IiEiPsdETERHpMTZ6IiIiPcZGT0REpMf+H6RjzFvgmOlrAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "plt.semilogy(snr_range, results)\n",
    "plt.xlabel('SNR(dB)')\n",
    "plt.ylabel('BER');\n",
    "plt.grid(which='major', alpha=0.5)\n",
    "plt.grid(which='minor', alpha=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorboard and @tf.function: create the model in a graph as in TF 1.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the decorator @tf.function before the call function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder_graph(Model):\n",
    "\n",
    "    def __init__(self, K, ch_uses=1, **kwargs):\n",
    "        super(Autoencoder_graph, self).__init__(**kwargs)\n",
    "        self.K = K\n",
    "        self.M = int(2**self.K)\n",
    "        self.ch_uses = ch_uses\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.encoder = Encoder(self.K, self.ch_uses)\n",
    "        self.channel = Channel()\n",
    "        self.decoder = Decoder(self.K)\n",
    "    \n",
    "    @tf.function\n",
    "    def call(self, inputs):\n",
    "        \n",
    "        self.bits, self.snr = inputs\n",
    "        \n",
    "        self.noise_std = tf.sqrt( 2 / tf.pow(10., self.snr/10.0))\n",
    "        \n",
    "        self.x = self.encoder(self.bits)\n",
    "        self.y = self.channel(self.x, self.noise_std)\n",
    "        self.b_hat = self.decoder(self.y)\n",
    "        \n",
    "        return self.b_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 4\n",
    "ch_uses = 1\n",
    "snr = 15\n",
    "\n",
    "autoencoder_graph = Autoencoder_graph(K, ch_uses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the model is created in a graph, then we can use `tf.summary.trace_on()` to view the graph on Tensorboard :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the writer for tensorboard\n",
    "current_time = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "train_log_dir = './logs/gradient_tape/' + current_time + '/train'\n",
    "train_summary_writer = tf.summary.create_file_writer(train_log_dir)\n",
    "\n",
    "#Do only one batch\n",
    "dataset = tf.data.Dataset.zip(generate_ds_bits(1, batch_size, K, snr))\n",
    "\n",
    "#Trace the model\n",
    "for step, (features, labels) in enumerate(dataset):\n",
    "    tf.summary.trace_on(graph=True, profiler=True)\n",
    "    b_hat_log = autoencoder_graph(features)\n",
    "    with train_summary_writer.as_default():\n",
    "        tf.summary.trace_export(\n",
    "            name=\"my_func_trace\",\n",
    "            step=0,\n",
    "            profiler_outdir=train_log_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualise the Tensorboard session, open a terminal (File -> New -> Terminal), go to the current folder, and type\n",
    "\n",
    "`tensorboard --logdir ./logs --bind_all`\n",
    "\n",
    "\n",
    "Then go to http://127.0.0.1:10001 or http://127.0.0.1:10002 (or ...) on your browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER after each epoch:\n",
      "0.101525, 0.065575, 0.043425, 0.03695, 0.0365, 0.0344, 0.035325, 0.034, 0.0334, 0.03485, \n",
      "\n",
      "Execution time : 11.545795202255249 seconds\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10000\n",
    "epoch_size = 100\n",
    "nb_epoch = 10\n",
    "\n",
    "# Create the writer for tensorboard\n",
    "current_time = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "train_log_dir = './logs/gradient_tape/' + current_time + '/train'\n",
    "train_summary_writer = tf.summary.create_file_writer(train_log_dir)\n",
    "\n",
    "#Initialise some metrics that we want to display in Tensorboard\n",
    "train_loss = tf.keras.metrics.Mean('train_loss', dtype=tf.float32)\n",
    "train_ber = tf.keras.metrics.Mean('train_BER', dtype=tf.float32)\n",
    "    \n",
    "print('BER after each epoch:')\n",
    "    \n",
    "start_time = time.time()\n",
    "for epoch in range(nb_epoch):\n",
    "    \n",
    "    # Create a dataset for each epoch\n",
    "    dataset = tf.data.Dataset.zip(generate_ds_bits(epoch_size, batch_size, K, snr))\n",
    "\n",
    "    # Iterate over the batches of the dataset.\n",
    "    for step, (features, labels) in enumerate(dataset):\n",
    "        # Open a GradientTape.\n",
    "        with tf.GradientTape() as tape:\n",
    "                        \n",
    "            # Forward pass.\n",
    "            b_hat_log = autoencoder_graph(features)\n",
    "\n",
    "            # Loss value for this batch.\n",
    "            loss_value =  loss_func(labels, b_hat_log, from_logits=True)\n",
    "            \n",
    "        # Get gradients of loss wrt the weights.\n",
    "        gradients = tape.gradient(loss_value, autoencoder_graph.trainable_weights)\n",
    "\n",
    "        # Update the weights of our linear layer.\n",
    "        optimizer.apply_gradients(zip(gradients, autoencoder_graph.trainable_weights))\n",
    "\n",
    "    b_hat = tf.cast(tf.sign(b_hat_log)/2+1, dtype=tf.int32)\n",
    "    ber = tf.reduce_sum(tf.abs(b_hat - labels))/(batch_size*K)\n",
    "    print(ber.numpy(), end=', ')\n",
    "    \n",
    "    #Write the metrics\n",
    "    with train_summary_writer.as_default():\n",
    "        train_loss(loss_value)\n",
    "        train_ber(tf.constant(ber))\n",
    "        tf.summary.scalar('loss', train_loss.result(), step=epoch)\n",
    "        tf.summary.scalar('BER', train_ber.result(), step=epoch)\n",
    "    #Reset the metrics\n",
    "    train_loss.reset_states()\n",
    "    train_ber.reset_states()\n",
    "        \n",
    "print(\"\\n\\nExecution time : %s seconds\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Don't hesitate to refresh the Tensorboard page to see the new metrics\n",
    "- The Tensorboard metrics can be called even when the model is not in a graph.\n",
    "- The execution is (much) faster, but you loose acces to the variables inside the graph :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"encoder_1/Complex:0\", shape=(10000, 1), dtype=complex64)\n",
      "\n",
      "/!\\ AttributeError: Tensor object has no attribute numpy\n"
     ]
    }
   ],
   "source": [
    "print(autoencoder_graph.x)\n",
    "\n",
    "try:\n",
    "    print(autoencoder_graph.x.numpy())\n",
    "except:\n",
    "    print('\\n/!\\ AttributeError: Tensor object has no attribute numpy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you decide to create graphs, you can also compile your model and use standard Keras function like fit() to train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "250/250 [==============================] - 3s 10ms/step - loss: 1.0558\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 0.3954\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 0.2591\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 0.1965\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 0.1965\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 0.1966\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 0.1615\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 0.1433\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 0.1273\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 0.1252\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f66e0549b70>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate an autoencoder\n",
    "autoencoder_graph_2 = Autoencoder_graph(K, ch_uses)\n",
    "\n",
    "#Initialise optimizer and loss function\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_func = tf.keras.losses.binary_crossentropy\n",
    "\n",
    "#Generate dataset\n",
    "batch_size = 10000\n",
    "epoch_size = 250\n",
    "nb_epoch = 10\n",
    "dataset = tf.data.Dataset.zip(generate_ds_bits(epoch_size, batch_size, K, snr))\n",
    "\n",
    "#Compile and fit\n",
    "autoencoder_graph_2.compile(optimizer, loss_func)\n",
    "autoencoder_graph_2.fit(dataset, epochs=nb_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"autoencoder_graph_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder (Encoder)            multiple                  32        \n",
      "_________________________________________________________________\n",
      "channel (Channel)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "decoder (Decoder)            multiple                  692       \n",
      "=================================================================\n",
      "Total params: 724\n",
      "Trainable params: 724\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder_graph_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
