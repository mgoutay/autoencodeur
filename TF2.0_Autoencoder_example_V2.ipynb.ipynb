{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Physical Layer as an Autoencoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First : change the runtime and hardware acceleration**\n",
    "\n",
    "Runtime $\\rightarrow$ Change runtime type\n",
    "\n",
    "- Runtime type : Python 3\n",
    "- Hardware accelerator : GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An autoencoder is a type of artificial neural network used to find a useful representation of some data $\\mathbf{s}$ at an intermediate layer $\\mathbf{x}$ through learning to reproduce the input at the output.\n",
    "\n",
    "![autoencoder_0](https://github.com/mgoutay/autoencodeur/blob/master/Images/autoencoder_0.png?raw=true)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install TensorFlow 2.0 on Google Collab if needed\n",
    "try:\n",
    "  # %tensorflow_version only exists in Colab.\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version:  2.0.0\n",
      "Number of GPUs available : 4\n",
      "Only GPU number 0 used\n"
     ]
    }
   ],
   "source": [
    "#Set the GPU you want to use\n",
    "num_GPU = 0\n",
    "\n",
    "import tensorflow as tf\n",
    "print('Tensorflow version: ', tf.__version__)\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "print('Number of GPUs available :', len(gpus))\n",
    "\n",
    "if num_GPU < len(gpus):\n",
    "    tf.config.experimental.set_visible_devices(gpus[num_GPU], 'GPU')\n",
    "    tf.config.experimental.set_memory_growth(gpus[num_GPU], True)\n",
    "    print('Only GPU number', num_GPU, 'used')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import sys\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt  \n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Layer, Dense, Lambda\n",
    "from tensorflow.keras.regularizers import Regularizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Communicating messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**An autoencoder-based communication systems aims to implement the transmitter, channel, and receiver as a single NN which reconstructs its input at its output**\n",
    "\n",
    "The goal is to learn a modulation wich will be robust with respect to the perturbations introduced by the channel.\n",
    "\n",
    "The channel is implemented as a \"Noise Layer\" without any learnable parameters, wich must be differentiable in order to perform SGD on the transmitter's parameters.\n",
    "\n",
    "Examples:\n",
    "\n",
    "- AWGN channel : $\\mathbf{y} = \\mathbf{x} + \\mathbf{w}$\n",
    "\n",
    "- Memoryless fading channel : $\\mathbf{y} = h \\mathbf{x} + \\mathbf{n} $\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![autoencoder](https://github.com/mgoutay/autoencodeur/blob/master/Images/autoencoder.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's transmit messages.\n",
    "\n",
    "The first hyper-parameters to set are the total number of messages $M$ and the number of channel uses $N_c$\n",
    "\n",
    "It can be seen that $M$ can also be seen as the modulation order. Indeed, sending one out of $M$ message is equivalent to sending $\\log_2(M)$ bits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will implement the fowllowing network:\n",
    "![model_0](https://github.com/mgoutay/autoencodeur/blob/master/Images/model_0.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transmitter(Layer):\n",
    "\n",
    "    def __init__(self, K, ch_uses=1, **kwargs):\n",
    "        super(Encoder, self).__init__(**kwargs)\n",
    "        self.M = int(2**self.K)\n",
    "        self.ch_uses = ch_uses\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.emb_table = self.add_weight(shape=[self.M, self.M], \n",
    "                                          initializer='random_normal',\n",
    "                                          trainable=True)\n",
    "\n",
    "    def call(self, messages):\n",
    "        self.x_0 = tf.nn.embedding_lookup(self.emb_table, messages)\n",
    "        \n",
    "        # Normalize power per symbol to 1\n",
    "        self.en_moy =tf.sqrt(2 * tf.reduce_mean(tf.square(self.emb_table)))\n",
    "        self.x_norm = tf.divide(self.x, self.en_moy)\n",
    "        \n",
    "        #Real to complex\n",
    "        self.x_cplx = tf.complex(self.x_norm[:, :int(self.ch_uses)], self.x_norm[:, int(self.ch_uses):])\n",
    "            \n",
    "        return self.x_cplx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of bits per symbols\n",
    "K = 4\n",
    "M = np.power(2, K)\n",
    "\n",
    "# Number of channel uses\n",
    "ch_uses = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(Layer):\n",
    "\n",
    "    def __init__(self, K, ch_uses=1, **kwargs):\n",
    "        super(Encoder, self).__init__(**kwargs)\n",
    "        self.K = K\n",
    "        self.M = int(2**self.K)\n",
    "        self.ch_uses = ch_uses\n",
    "        self.bin_conv = tf.convert_to_tensor(np.flip([np.power(2, i) for i in range(self.K)]).astype(np.int32)) # (8, 4, 2, 1)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.emb_table = self.add_weight(shape=[self.M, 2*self.ch_uses], \n",
    "                                          initializer='random_normal',\n",
    "                                          trainable=True)\n",
    "\n",
    "    def call(self, bits):\n",
    "        self.bits_k = tf.reshape(bits, [-1, self.K])\n",
    "        self.s = tf.reduce_sum(self.bits_k*tf.expand_dims(self.bin_conv,axis= 0), axis=1)\n",
    "        self.x = tf.nn.embedding_lookup(self.emb_table, self.s)\n",
    "        \n",
    "        # Normalize power per symbol to 1\n",
    "        self.en_moy =tf.sqrt(2 * tf.reduce_mean(tf.square(self.emb_table)))\n",
    "        self.x_norm = tf.divide(self.x, self.en_moy)\n",
    "        #Real to complex\n",
    "        self.x_cplx = tf.complex(self.x_norm[:, :int(self.ch_uses)], self.x_norm[:, int(self.ch_uses):])\n",
    "            \n",
    "        return self.x_cplx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Channel(Layer):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Channel, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, x, noise_std):\n",
    "            \n",
    "        self.noise_r = tf.random.normal(shape = tf.shape(x), stddev = 1) * noise_std/tf.sqrt(2.)\n",
    "        self.noise_i = tf.random.normal(shape = tf.shape(x), stddev = 1) * noise_std/tf.sqrt(2.)\n",
    "        self.noise_cplx = tf.complex(self.noise_r, self.noise_i, name=\"noise\")\n",
    "        \n",
    "        self.y = x + self.noise_cplx\n",
    "            \n",
    "        return self.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(Layer):\n",
    "\n",
    "    def __init__(self, K, **kwargs):\n",
    "        super(Decoder, self).__init__(**kwargs)\n",
    "        self.K = K\n",
    "        self.M = int(2**self.K)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.dense_0 = Dense(2*self.M, activation = tf.nn.relu)\n",
    "        self.dense_1 = Dense(self.M, activation = tf.nn.relu)\n",
    "        self.dense_2 = Dense(self.K, activation = None)\n",
    "\n",
    "    def call(self, y):\n",
    "        \n",
    "        self.y_real = tf.concat([tf.math.real(y), tf.math.imag(y)], axis=1)\n",
    "        self.d_0 = self.dense_0(self.y_real)\n",
    "        self.d_1 = self.dense_1(self.d_0)\n",
    "        self.d_2 = self.dense_2(self.d_1)\n",
    "        self.b_hat = tf.reshape(self.d_2, [-1])\n",
    "        \n",
    "        return self.b_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(Model):\n",
    "\n",
    "    def __init__(self, K, ch_uses=1, **kwargs):\n",
    "        super(Autoencoder, self).__init__(**kwargs)\n",
    "        self.K = K\n",
    "        self.M = int(2**self.K)\n",
    "        self.ch_uses = ch_uses\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.encoder = Encoder(self.K, self.ch_uses)\n",
    "        self.channel = Channel()\n",
    "        self.decoder = Decoder(self.K)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        \n",
    "        self.bits, self.snr = inputs\n",
    "        \n",
    "        self.noise_std = tf.sqrt( 2 / tf.pow(10., self.snr/10.0))\n",
    "        \n",
    "        self.x = self.encoder(self.bits)\n",
    "        self.y = self.channel(self.x, self.noise_std)\n",
    "        self.b_hat = self.decoder(self.y)\n",
    "        \n",
    "        return self.b_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instantiate an  autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SNR at training\n",
    "snr = 15\n",
    "\n",
    "# Instantiate an autoencoder\n",
    "autoencoder = Autoencoder(K, ch_uses)\n",
    "\n",
    "#Initialize optimizer and loss function\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_func = tf.keras.losses.binary_crossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ds_bits(epoch_len, batch_size, K, snr):\n",
    "    'Generate a dataset for training'\n",
    "    rand_bits = tf.random.uniform(shape=[epoch_len, batch_size*K], minval=0, maxval=2, dtype=tf.int32)\n",
    "    bits_ds = tf.data.Dataset.from_tensor_slices(rand_bits)\n",
    "    snr_ds = tf.data.Dataset.from_tensor_slices(snr*tf.ones(shape=[epoch_len, batch_size, 1]))\n",
    "    \n",
    "    features_ds = tf.data.Dataset.zip((bits_ds, snr_ds))\n",
    "    labels_ds = tf.data.Dataset.from_tensor_slices(rand_bits)\n",
    "    return (features_ds, labels_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER after each epoch:\n",
      "0.20965, 0.1574, 0.115525, 0.091375, 0.06895, 0.053125, 0.04455, 0.040375, 0.039375, 0.035125, \n",
      "\n",
      "Execution time : 19.777037143707275 seconds\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10000\n",
    "epoch_size = 100\n",
    "nb_epoch = 10\n",
    "\n",
    "print('BER after each epoch:')\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(nb_epoch):\n",
    "    \n",
    "    # Create a dataset for each epoch\n",
    "    dataset = tf.data.Dataset.zip(generate_ds_bits(epoch_size, batch_size, K, snr))\n",
    "\n",
    "    # Iterate over the batches of the dataset.\n",
    "    for step, (features, labels) in enumerate(dataset):\n",
    "        # Open a GradientTape.\n",
    "        with tf.GradientTape() as tape:\n",
    "\n",
    "            # Forward pass.\n",
    "            b_hat_log = autoencoder(features)\n",
    "\n",
    "            # Loss value for this batch.\n",
    "            loss_value =  loss_func(labels, b_hat_log, from_logits=True)\n",
    "\n",
    "        # Get gradients of loss wrt the weights.\n",
    "        gradients = tape.gradient(loss_value, autoencoder.trainable_weights)\n",
    "\n",
    "        # Update the weights of our linear layer.\n",
    "        optimizer.apply_gradients(zip(gradients, autoencoder.trainable_weights))\n",
    "\n",
    "    b_hat = tf.cast(tf.sign(b_hat_log)/2+1, dtype=tf.int32)\n",
    "    ber = tf.reduce_sum(tf.abs(b_hat - labels))/(batch_size*K)\n",
    "    print(ber.numpy(), end=', ')\n",
    "\n",
    "print(\"\\n\\nExecution time : %s seconds\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# See learned constellation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now directly see what's inside each class :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.7658981 -0.04487091j]\n",
      " [-0.26066825+0.7347326j ]\n",
      " [ 1.250048  -0.14272638j]\n",
      " ...\n",
      " [ 0.05869472+1.1574969j ]\n",
      " [-0.25172818-0.11254451j]\n",
      " [ 0.6742501 +0.2404414j ]]\n"
     ]
    }
   ],
   "source": [
    "x = autoencoder.x.numpy()\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f66e04d8d68>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.style.use('dark_background')\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(np.real(x), np.imag(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bits(batch_size, K):\n",
    "    'Generate a batch for evaluating'\n",
    "    rand_bits = tf.random.uniform(shape=[batch_size*K], minval=0, maxval=2, dtype=tf.int32)\n",
    "    features = rand_bits\n",
    "    labels = rand_bits\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, "
     ]
    }
   ],
   "source": [
    "snr_range = np.arange(-5, 26)\n",
    "results=[]\n",
    "bs_eval = 100000\n",
    "\n",
    "for snr in snr_range:\n",
    "    features, labels = generate_bits(bs_eval, K)\n",
    "    b_hat_log = autoencoder([features, snr])\n",
    "    b_hat = tf.cast(tf.sign(b_hat_log)/2+1, dtype=tf.int32)\n",
    "    ber = tf.reduce_sum(tf.abs(b_hat - labels))/(bs_eval*K)\n",
    "    results.append(ber.numpy())\n",
    "    print(snr, end=', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "plt.semilogy(snr_range, results)\n",
    "plt.xlabel('SNR(dB)')\n",
    "plt.ylabel('BER');\n",
    "plt.grid(which='major', alpha=0.5)\n",
    "plt.grid(which='minor', alpha=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorboard and @tf.function: create the model in a graph as in TF 1.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the decorator @tf.function before the call function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder_graph(Model):\n",
    "\n",
    "    def __init__(self, K, ch_uses=1, **kwargs):\n",
    "        super(Autoencoder_graph, self).__init__(**kwargs)\n",
    "        self.K = K\n",
    "        self.M = int(2**self.K)\n",
    "        self.ch_uses = ch_uses\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.encoder = Encoder(self.K, self.ch_uses)\n",
    "        self.channel = Channel()\n",
    "        self.decoder = Decoder(self.K)\n",
    "    \n",
    "    @tf.function\n",
    "    def call(self, inputs):\n",
    "        \n",
    "        self.bits, self.snr = inputs\n",
    "        \n",
    "        self.noise_std = tf.sqrt( 2 / tf.pow(10., self.snr/10.0))\n",
    "        \n",
    "        self.x = self.encoder(self.bits)\n",
    "        self.y = self.channel(self.x, self.noise_std)\n",
    "        self.b_hat = self.decoder(self.y)\n",
    "        \n",
    "        return self.b_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 4\n",
    "ch_uses = 1\n",
    "snr = 15\n",
    "\n",
    "autoencoder_graph = Autoencoder_graph(K, ch_uses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the model is created in a graph, then we can use `tf.summary.trace_on()` to view the graph on Tensorboard :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the writer for tensorboard\n",
    "current_time = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "train_log_dir = './logs/gradient_tape/' + current_time + '/train'\n",
    "train_summary_writer = tf.summary.create_file_writer(train_log_dir)\n",
    "\n",
    "#Do only one batch\n",
    "dataset = tf.data.Dataset.zip(generate_ds_bits(1, batch_size, K, snr))\n",
    "\n",
    "#Trace the model\n",
    "for step, (features, labels) in enumerate(dataset):\n",
    "    tf.summary.trace_on(graph=True, profiler=True)\n",
    "    b_hat_log = autoencoder_graph(features)\n",
    "    with train_summary_writer.as_default():\n",
    "        tf.summary.trace_export(\n",
    "            name=\"my_func_trace\",\n",
    "            step=0,\n",
    "            profiler_outdir=train_log_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualise the Tensorboard session, open a terminal (File -> New -> Terminal), go to the current folder, and type\n",
    "\n",
    "`tensorboard --logdir ./logs --bind_all`\n",
    "\n",
    "\n",
    "Then go to http://127.0.0.1:10001 or http://127.0.0.1:10002 (or ...) on your browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER after each epoch:\n",
      "0.101525, 0.065575, 0.043425, 0.03695, 0.0365, 0.0344, 0.035325, 0.034, 0.0334, 0.03485, \n",
      "\n",
      "Execution time : 11.545795202255249 seconds\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10000\n",
    "epoch_size = 100\n",
    "nb_epoch = 10\n",
    "\n",
    "# Create the writer for tensorboard\n",
    "current_time = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "train_log_dir = './logs/gradient_tape/' + current_time + '/train'\n",
    "train_summary_writer = tf.summary.create_file_writer(train_log_dir)\n",
    "\n",
    "#Initialise some metrics that we want to display in Tensorboard\n",
    "train_loss = tf.keras.metrics.Mean('train_loss', dtype=tf.float32)\n",
    "train_ber = tf.keras.metrics.Mean('train_BER', dtype=tf.float32)\n",
    "    \n",
    "print('BER after each epoch:')\n",
    "    \n",
    "start_time = time.time()\n",
    "for epoch in range(nb_epoch):\n",
    "    \n",
    "    # Create a dataset for each epoch\n",
    "    dataset = tf.data.Dataset.zip(generate_ds_bits(epoch_size, batch_size, K, snr))\n",
    "\n",
    "    # Iterate over the batches of the dataset.\n",
    "    for step, (features, labels) in enumerate(dataset):\n",
    "        # Open a GradientTape.\n",
    "        with tf.GradientTape() as tape:\n",
    "                        \n",
    "            # Forward pass.\n",
    "            b_hat_log = autoencoder_graph(features)\n",
    "\n",
    "            # Loss value for this batch.\n",
    "            loss_value =  loss_func(labels, b_hat_log, from_logits=True)\n",
    "            \n",
    "        # Get gradients of loss wrt the weights.\n",
    "        gradients = tape.gradient(loss_value, autoencoder_graph.trainable_weights)\n",
    "\n",
    "        # Update the weights of our linear layer.\n",
    "        optimizer.apply_gradients(zip(gradients, autoencoder_graph.trainable_weights))\n",
    "\n",
    "    b_hat = tf.cast(tf.sign(b_hat_log)/2+1, dtype=tf.int32)\n",
    "    ber = tf.reduce_sum(tf.abs(b_hat - labels))/(batch_size*K)\n",
    "    print(ber.numpy(), end=', ')\n",
    "    \n",
    "    #Write the metrics\n",
    "    with train_summary_writer.as_default():\n",
    "        train_loss(loss_value)\n",
    "        train_ber(tf.constant(ber))\n",
    "        tf.summary.scalar('loss', train_loss.result(), step=epoch)\n",
    "        tf.summary.scalar('BER', train_ber.result(), step=epoch)\n",
    "    #Reset the metrics\n",
    "    train_loss.reset_states()\n",
    "    train_ber.reset_states()\n",
    "        \n",
    "print(\"\\n\\nExecution time : %s seconds\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Don't hesitate to refresh the Tensorboard page to see the new metrics\n",
    "- The Tensorboard metrics can be called even when the model is not in a graph.\n",
    "- The execution is (much) faster, but you loose acces to the variables inside the graph :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"encoder_1/Complex:0\", shape=(10000, 1), dtype=complex64)\n",
      "\n",
      "/!\\ AttributeError: Tensor object has no attribute numpy\n"
     ]
    }
   ],
   "source": [
    "print(autoencoder_graph.x)\n",
    "\n",
    "try:\n",
    "    print(autoencoder_graph.x.numpy())\n",
    "except:\n",
    "    print('\\n/!\\ AttributeError: Tensor object has no attribute numpy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you decide to create graphs, you can also compile your model and use standard Keras function like fit() to train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "250/250 [==============================] - 3s 10ms/step - loss: 1.0558\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 0.3954\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 0.2591\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 0.1965\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 0.1965\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 0.1966\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 0.1615\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 0.1433\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 0.1273\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 0.1252\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f66e0549b70>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate an autoencoder\n",
    "autoencoder_graph_2 = Autoencoder_graph(K, ch_uses)\n",
    "\n",
    "#Initialise optimizer and loss function\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_func = tf.keras.losses.binary_crossentropy\n",
    "\n",
    "#Generate dataset\n",
    "batch_size = 10000\n",
    "epoch_size = 250\n",
    "nb_epoch = 10\n",
    "dataset = tf.data.Dataset.zip(generate_ds_bits(epoch_size, batch_size, K, snr))\n",
    "\n",
    "#Compile and fit\n",
    "autoencoder_graph_2.compile(optimizer, loss_func)\n",
    "autoencoder_graph_2.fit(dataset, epochs=nb_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"autoencoder_graph_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder (Encoder)            multiple                  32        \n",
      "_________________________________________________________________\n",
      "channel (Channel)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "decoder (Decoder)            multiple                  692       \n",
      "=================================================================\n",
      "Total params: 724\n",
      "Trainable params: 724\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder_graph_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
